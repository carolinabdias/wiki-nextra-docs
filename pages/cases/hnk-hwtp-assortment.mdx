[[_TOC_]]
# Assortment

## Business context
The idea behind this project is to make the definition of the restricted sales plan more automatic. Some brands in Heineken were facing a profitability issues, so the goal is to develop a model which could better allocate SKU’s volume within the CDAs in order to maximize brand’s profitability. This would be done considering overall functional gross profit, as well as a storage, sellout and sales plan restrictions.


## Use-case
Make a recommendation of how much of each product should be sent to each CDA in order to achieve the highest possible FGP for a brand.

## Scope
The final recommendation is made for SKUs in all Heineken CDAs. 

## POC Design Architecture
![imagem solution design](assets\images\hwtp_sd.png)

![image.png](/.attachments/image-1218b362-0109-4496-83c2-52afec186635.png)
## Dataflow

::: mermaid
 graph LR;
 A[Update sellout table] --> B[Join tables];
 C[Update transport table] --> B[Join tables];
 D[Update stock table] --> B[Join tables];
 E[Update stockout table] --> B[Join tables];
 F[Update holidays table] --> B[Join tables];
 B[Join tables] --> H[Make sellout predictions];
 H[Make sellout predictions] --> I[Calculate sellout interval];
 I[Calculate sellout interval] --> J[Update sales plan restriction];
 I[Calculate sellout interval] --> K[Update storage restriction];
 I[Calculate sellout interval] --> L[Update FGP/HL values];
 J[Update sales plan restriction] --> M[Make optimization];
 K[Update storage restriction] --> M[Make optimization];
 L[Update FGP/HL values] --> M[Make optimization];
:::

## Sellout forecast
### 1. Overview
The goal of the final optimization is to recommend a monthly amount of product that should be sent to each CDA in order to achieve the highest FGP possible. A forecast model has been included as part of the optimization process in order to define sellout upper and lower bounds for the final recommendation.

It should be notes that the idea of a sellout forecast is also present in the CSLP Stockout prediction project, and many structure-related decisions for this project have been inherited from it. One of them being the model and error types used: the XGBoost and the DTW, respectively. There are also many features the two have in common, such as the sellout lags and rolling averages, in addition to information from the stock and transport tables. Considering both cases use the XGBoost model to make time-series predictions - for which the model isn't natively adapted to do - they also share the fact of using a steps-based prediction in order to predict more than one value in the future. This is being noted so you know to refer to the [Stockout Prediction technical notes](/DDI%2DStockoutPrediction) for complementary  information related to the forecast process or preprocessing of the tables used.

An important aspect of this particular problem is the fact that the predictions are made on a week basis. Since the model should output a month sellout volume, this means this prediction takes five steps (overall duration of a month) and all daily features should be grouped accordingly. As part of this process, a convention was defined: the date used to represent a week is the **Sunday at the end of it**, for instance: the total sellout of the days 26/09/2022 - 30/09/2022 will be on the _sellout_sum_ column on the row of the _date_week_ 02/10/2022. It should also be noted that as part of the preprocessing of the data, all information regarding Saturdays and Sundays have been removed from the dataset (a decision inherited from the Stockout Prediction project as well). 
 
Once the five predictions are done, their values should be used to calculate a lower and upper bounds of the possible sellout volume a CDA might have in a month. The overall process goes through the following steps:
1. Predict the sellout for five steps in the future, where each predicted sellout refers to the total amount of sellout in a week the CDA should have.
2. For each step, lower and upper limits are calculated, creating an underestimated sellout series and an overestimated sellout series.
3. The five underestimated sellout steps are added to define the CDA's lower sellout restriction, and the overestimated steps define the upper sellout restriction.

### 2. Features
Listed below are the final features present in the model. It should be noted the tool used for their selection is the SHAP-values plot: the features kept were the 25 deemed most relevant to the target variable.

<table>
<thead>
  <tr>
    <th>Feature Type</th>
    <th>Feature Name</th>
    <th>Data Type</th>
    <th>Description</th>
    <th>Data Source</th>
    <th>Script Location</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>Target</td>
    <td>sellout_sum</td>
    <td>Float</td>
    <td>Total volume to be sold of a specific CDA/SKU pairing</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td rowspan="9">Sellout-related</td>
    <td>sellout_sum_lag_1</td>
    <td>Float</td>
    <td>Sellout volume for W-1</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_sum_lag_2</td>
    <td>Float</td>
    <td>Sellout volume for W-2</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_sum_lag_3</td>
    <td>Float</td>
    <td>Sellout volume for W-3</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_sum_lag_4</td>
    <td>Float</td>
    <td>Sellout volume for W-4</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_sum_lag_5</td>
    <td>Float</td>
    <td>Sellout volume for W-5</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_sum_lag_6</td>
    <td>Float</td>
    <td>Sellout volume for W-6</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_rol_avg_2</td>
    <td>Float</td>
    <td>Sellout rolling average of last 2 weeks from W-1</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_rol_avg_3</td>
    <td>Float</td>
    <td>Sellout rolling average of last 3 weeks from W-1</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>sellout_rol_avg_5</td>
    <td>Float</td>
    <td>Sellout rolling average of last 5 weeks from W-1</td>
    <td>fdmovimentacaoestoque</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td rowspan="10">Stock-related</td>
    <td>stock_monday</td>
    <td>Float</td>
    <td>Stock of a SKU on a CDA at the start of Monday</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_1</td>
    <td>Float</td>
    <td>Monday stock from W-1</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_2</td>
    <td>Float</td>
    <td>Monday stock from W-2</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_3</td>
    <td>Float</td>
    <td>Monday stock from W-3</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_4</td>
    <td>Float</td>
    <td>Monday stock from W-4</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_5</td>
    <td>Float</td>
    <td>Monday stock from W-5</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_6</td>
    <td>Float</td>
    <td>Monday stock from W-6</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_7</td>
    <td>Float</td>
    <td>Monday stock from W-7</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_8</td>
    <td>Float</td>
    <td>Monday stock from W-8</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>stock_monday_lag_9</td>
    <td>Float</td>
    <td>Monday stock from W-9</td>
    <td>estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>Transport-related</td>
    <td>deliveries_sum</td>
    <td>Float</td>
    <td>Total volume of deliveries in the week for a SKU to a CDA </td>
    <td>se_ds_ds_zmm191_trans</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>Transport/stock-related</td>
    <td>stock_plus_del</td>
    <td>Float</td>
    <td>Sum of deliveries and Monday stock for a CDA/SKU</td>
    <td>se_ds_ds_zmm191_trans/estoquediario</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td rowspan="4">Calendar-related</td>
    <td>week_of_year</td>
    <td>Integer</td>
    <td>Number of week in year</td>
    <td>Calculated from date</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>week_of_month</td>
    <td>Integer</td>
    <td>Number of week in month</td>
    <td>Calculated from date</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>month</td>
    <td>Integer</td>
    <td>Month number</td>
    <td>Calculated from date</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
  <tr>
    <td>holidays</td>
    <td>Float</td>
    <td>Average number of holidays in week</td>
    <td>Calculated from holidays API</td>
    <td>features/sellout_forecast_features.py</td>
  </tr>
</tbody>
</table>

The SHAP-values algorithm only takes one model whose features should be ranked, and since there is one XGBoost model for each CDA/sku pairing, this process was made with a single model trained on the entire features dataset.

Other features that were experimented but eventually ended deprecated:
- Maximum and average temperature in the week - very little improvement in error
- Total precipitation volume in the week - very little improvement in error
- A boolean flag indicating a holiday in the following week - no improvement in error
- Stock times deliveries sum - redundant with stock plus deliveries, which had a better correlation to sellout
- Demographics (such as average wage and population age groups) - didn't vary over time, so didn't improve error
- Inflation - not granular enough


### 3. The recursive forecast
There was one challenge associated with the usage of the XGBoost model for forecasting: the fact that it is not a model designed to make predictions with several steps ahead, just one. To contour that, a recursive prediction structure was implemented. In a nutshell, that
means the model will do a regular prediction for the first step in the forecast horizon, using real historical data to do it. For the second step in prediction, however, part of the data will be real, and part will be the predicted data from the previous day. As the model approaches the last steps in the forecast horizon, more of its estimations will be done based off of previous estimations instead of actual data. This means that, for the 5-week forecast horizon, the predicted sellout for the first weeks was more accurate than the last few.

The picture below helps to show the structure of the recursive prediction: assuming today is January 8th, the data in the databases used is consolidated up until January 7th (yesterday). Therefore, for today’s prediction, all features – such as yesterday’s data, last week’s sellout, stock information from two weeks ago – everything is real, the numbers depict something that actually happened. For predicting tomorrow, however, that is not all true: last week’s sellout is still factual, but for yesterday’s sellout the model will receive a predicted value as
input.

As for the model features that are not sellout-related, since their value is not being predicted, are dealt with differently. _sum_deliveries_, the feature that represents the volume of a product being received by a CDA, is looked up directly from the order deliveries database, since it is the only table that contains future deliveries. The stock for a day is calculated using data from the day before, as such:

$𝑆𝑇𝑂𝐶𝐾
𝐷 = 𝑆𝑇𝑂𝐶𝐾
𝐷−1 + 𝑄𝑇𝐷_𝑅𝐸𝑀𝐸𝑆𝑆𝐴
𝐷−1 − 𝑆𝐸𝐿𝐿𝑂𝑈𝑇
𝐷−1$

Lag features up until 5 are updated for each iteration, for instance: once sellout has been predicted for January 8th, it is stored as sellout_lag_1 for the prediction for January 9th. The other features used are kept as the same value for the day exactly one week before, meaning, for example, that the stock moving average considered for predicting January 9th has the same value as for January 2nd.

One more rule that was placed in between the steps in order to avoid inconsistencies in the sellout forecast was that no predicted value could be higher or lower than has ever happened in the history of that time series. For a 

![image.png](/.attachments/image-f2c4e4b7-c71e-4d56-9265-7fa852742dc8.png)

### 4. The upper and lower sellout bounds
Once the prediction results are available, it is time to calculate the minimum and maximum sellout which will later be used in the optimization process.

Since the optimization intends to allocate the most amount of product in the CDAs with the highest FGP/HL, there are a few adaptations which should be made to avoid unwanted side effects. The fact that the product distribution is made with the mindset that most profitable CDAs have a preference when it comes to receiving a product means the model could recommend directing 100% of the available volume of a sku to a CDA  in detriment of a less profitable one. So the minimum sellout restriction intends to make sure no market share is lost. The maximum sellout restriction, on the other hand, is placed to avoid an oversupply of the CDAs, which could lead to product left unsold.

The rule chosen to calculate the interval was to use the standard deviation of the time series to create an interval around the prediction itself. This means the value would be individualized for every CDA/sku time-series, and it would be simple enough to calculate, since it is a simple addition operation. A strategy to use models that returned a prediction within a confidence interval (more on this in Appendix C) was considered and tested, but deemed too complicated and didn't seem like much of an improvement from the standard deviation results.

The overall process of making the sellout restrictions goes as follows:
1. For a CDA/sku time series, a prediction would be made based on real historical data
2. From the first prediction, four forecast steps would be made recursively
3. Once a sellout prediction has been defined for each week in the prediced timeframe, an upper and lower bound would be calculated, using one (or less, defined by an $\sigma$ parameter*) standard deviation of the series itself
4. If the resulting upper bound surpasses the maximum sellout in the history of the time series, it is reduced so it is coherent with the rest of the series. The same is done for the lower bound in reference to the minimum historical sellout.
5. Once all upper and lower bounds have been calculated and adjusted, all lower bound sellout points are added to define the minimum sellout restriction, and all upper bound sellout points define the maximum sellout restriction 

#### The definition of $\sigma$

The * present in step 3 refers to an important concern caused a slight adjustement to this strategy: it is possible that the model could recommend a volume of a product in the CDA it couldn't sell due to a market saturation. This is partially addressed by the comparison of the calculated upper bound to the maximum historical sellout (in step 4), but it was decided to use a stockout frequency information to complement it.

The reasoning behind this decision is the conclusion that a CDA with high incidence of stockout means it could sell more of a certain product, but it doesn't due to a lack of supply. A CDA with a low frequency of stockout, on the other hand, most likely couldn't have a higher sellout volume even if it had product to spare. This idea would be represented by the $\sigma$ parameter: it would be closer to one when a CDA could absorb a higher amount of product, ie, when it has a high stockout frequency, and closer to zero when it couldn't, making the upper sellout limit close to the prediction itself. For each point in the sellout forecast, the limits would be defined as:

$Sellout_{lower} = Sellout_{predicted} -\sigma\times std$
$Sellout_{uppper} = Sellout_{predicted} + \sigma\times std$

The value which $\sigma$ would have is the result of the stockout frequency of a CDA/sku series passed through a sigmoid function. The stockout frequency is calculated for a period of time by the amount of days where a stockout happened (meaning stockout volume greater than zero, excluding weekends) divided by the total days passed. This number (from 0 to 100) gets passed though the sigmoid below to become a number between 0 and 1. 

This is a regular sigmoid function which was modified so that the mean stockout frequency would have an image of 0.5. The mean stockout frequency for all time series data is about 14.1%, meaning all CDA/sku pairings which have this frequency have their upper sellout bound set to about half of a standard deviation above the actual prediction. The frequency for which the upper bound is kept close to the actual prediction is about 8%, and the ones which have a full standard deviation added have about an 18% stockout frequency.

![image.png](/.attachments/image-a00cf816-38af-4e21-9136-b9c035466511.png)

Here is an example of a before/after sellout bounds with the $\sigma$ parameter:
![image.png](/.attachments/image-998ac222-27fd-402d-8391-c24fb3e8c7e1.png)
The CDA of Guarulhos has a relatively low stockout frequency for Amstel Ultra (about 3%). In the before scenario, its upper limit is high in comparison to the predicted values due to the fact that the time series has a high standard deviation overall. The picture on the right depicts a much more conservative upper limit.

## Optimization
### 1. Overview
The goal of the optimization is to recommend the amount of product each CDA should receive of each sku in order to maximize a brand's total FGP for a month. A dual simplex algorithm was chosen as a solver, since it was developed with linear problems in sight, is quick, and simple to use. It is a part of the SciPy library, and its documentation can be found [here](https://docs.scipy.org/doc/scipy/reference/optimize.linprog-highs-ds.html). 

The equations this algorithm can take use the following rules, where the first one is the actual objective function and the others refer to restrictions.

![image.png](/.attachments/image-74b8cba0-7683-4138-beed-12393a9bf081.png)

For this problem, $x$ is the amount of product a CDA should receive, at a CDA-sku-factory granularity. $c$ is the vector which contains all FGP/HL values in order to determine the overall FGP. One should point out that, since the algorithm is programmed to find a minimum, all FGP/HL values should have their values multiplied by -1 so that the result of the algoritm is a maximum instead.

There are no equality constraints and no lower or upper bounds for the value of $x$ itself, so all restrictions should be represented as the inequation on the second line in the picture above.  


### 2. Features
Here is a list of all information needed to perform the optimization and where they're acquired from:

<table>
<thead>
  <tr>
    <th>Feature Type</th>
    <th>Feature Name</th>
    <th>Data Type</th>
    <th>Restriction Type</th>
    <th>Granularity</th>
    <th>Description</th>
    <th>Data Source</th>
    <th>Script Location</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td rowspan="4">Restriction</td>
    <td>cda_max_stock</td>
    <td>Float</td>
    <td>Maximum</td>
    <td>CDA</td>
    <td>Total maximum volume a CDA has had in a month</td>
    <td>estoquediario</td>
    <td>optimization/restrictions.py</td>
  </tr>
  <tr>
    <td>sales_plan</td>
    <td>Float</td>
    <td>Maximum</td>
    <td>Factory-SKU</td>
    <td>Available volume a factory has of a SKU for the CDAs</td>
    <td>Sharepoint/Ciclo S&amp;OP</td>
    <td>optimization/restrictions.py</td>
  </tr>
  <tr>
    <td>predicted_sellout_sum_upper</td>
    <td>Float</td>
    <td>Maximum</td>
    <td>CDA-SKU</td>
    <td>Maximum volume a CDA should be able to sell of a SKU</td>
    <td>Result from sellout forecast</td>
    <td>optimization/restrictions.py</td>
  </tr>
  <tr>
    <td>predicted_sellout_sum_lower</td>
    <td>Float</td>
    <td>Minimum</td>
    <td>CDA-SKU</td>
    <td>Minimum volume a CDA should be able to sell of a SKU</td>
    <td>Result from sellout forecast</td>
    <td>optimization/restrictions.py</td>
  </tr>
  <tr>
    <td>Objective function</td>
    <td>fgp_weighted_average</td>
    <td>Float</td>
    <td>-</td>
    <td>CDA-SKU-Factory</td>
    <td>FGP/HL for a CDA-SKU-Factory calculated from the P&amp;L</td>
    <td>fact_plmanagerial</td>
    <td>optimization/fgp_hl_info.py</td>
  </tr>
</tbody>
</table>

#### 2.1 FGP/HL calculation
A value of FGP/HL should be determined to each CDA/sku/factory in order to define the objective function of the optimization problem. This information was calculated from the P&L Managerial table, which contains monthly financial indicators at a CDA/sku level. For CDAs which can receive its supply from more than one factory, the same FGP/HL calculated was used, since the table does not contain information at a factory level. 

The calculation of the FGP/HL value for each CDA/sku is a simple mean of the last six months consolidated in the table. It is important to point out that the complete financial results for a month are only considered to be fully updated in the managerial about halfway through the following month (ie, the results for November could only be considered reliable at about the middle to end of December, so a model run in November to make a recommendation to December would use the financial indicators from April to September).

The decision to use a simple mean as an estimation of FGP/HL came from a comparison of the overall FGP/HL to their components (also present in the P&L table) per HL. Most of them seemes coherent, with the exception of discounts to customer. It often wasn't coherent with the values for previous months and, as detailed by the team, is a value that although had a planned value in advance, could be altered upon demand as a strategic decision. Therefore, for this value specifically, a three-month mean was used (this was altered by removing the contribution of the discounts at a six-month mean and adding the three-month mean value, like so: $FGP/HL_{new} = FGP/HL_{old} - discounts/HL_{6} + discounts/HL_{3}$ 

#### 2.2 Storage restriction
The storage restriction is calculated at a CDA level only. A storage limit table was uploaded manually to databricks, which contains the information at a CDA/SKU level. It is then filtered to only include the SKUs being considered for the optimization and aggregated to form the CDA restriction. For instance, if Amstel 269mL and Amstel Ultra are the only skus being optimized, the stock table is filtered to only contain information regarding these two skus. Then, the stock for both of them are added up (so there is no distiction as to which sku has occupied which volume in the CDA) and the result is used as the maximum storage restriction for that CDA.

#### 2.3 Sales plan restriction
The sales plan restriction is the only one that is acquired manually at this point. It derives from the sales plan the team builds which contains the volume of all skus intended to be sent to each CDA, and from which factory. For the optimization, however, the information needed is the amount of product each factory has and which CDAs they can supply, _not the volume each CDA should receive (as this recommendation is the output of the optimization itself)_.

So, in order to become the sales plan restriction, two separate operations have to be performed:
1. The original table is grouped by factory/sku to become the restriction itself (as the total amount of product a factory has available to send to the CDAs)
2. A table of all CDAs/skus/factories is stored as a list of all possible routes available from the factories.

![image.png](/.attachments/image-339ac155-bcd9-43a2-a137-09a8d93632a4.png)

### 3. The restrictions inequations
Once all restriction tables are organized, there's one thing that should be borne in mind when implementing an optimization problem: as made explicit by the inequation in section 1 of the optimization, all restrictions have to be written in the granilarity of $x$, which is CDA/sku/factory.

The FGP/HL information is adapted from a CDA/sku granulatiry to CDA/sku/factory by a simple repetition of values, as stated previously. All other restrictions, however, need to have the logic of adding the right components to make a coherent inequation, which should be made by filling the $A_{ub}$ matrix with 0 and 1 to do the selection. Consider the sellout restriction, which is made at a CDA/sku level. In this case, the restriction is valid regardless of factory, so the restriction for CDA Guarulhos/Amstel 269mL should add the volumes for both Itu and Ponta Grossa (in color blue below). The storage restriction should consider all skus for a CDA (in color green), and the sales plan should be used for all CDAs which are supplied of a sku by the same factory (in yellow below). The 0 and 1s in the table, collectively, make up for the final $A_{ub}$ matrix.

One more thing that should be noted is the fact that the highs algorithm is made for all upper bound restrictions, so the minimum sellout restriction, much like the FGP/HL information, should have its coefficients negative (second line in table below).

![image.png](/.attachments/image-f351c427-2fb7-44e1-8771-e5d53e296585.png)

### 4. The infeasible problem
The last part of the optimization algorithm to be addressed is the fact that with so many restrictions, there happened to be configurations of upper and lower bound restrictions which eventually would make the problem infeasible. This conflict happened mostly between the maximum sales plan and minimum sellout constraints. If, for instance, the Itu factory has 25HL of Amstel 269mL available to sell for both CDA Guarulhos and CDA Campinas, there would be a problem if the minimum sellout for each of these CDAs were to be 20HL (higher than the total sales plan).

In order to avoid that from happening, a new step in the optimization was added: if the original conditions resulted in an infeasible problem, the minimum sellout of the CDA/sku pairings blocking the solution would be lowered by 10%. Then the optimization would try to run again, and if the problem occured again, the lowered sellout limit would be lowered by another 10% as many times as needed in order to make the problem feasible.

## The results
The final results of the model are available in the HWTP dash, updated monthly on the Power BI tool. Ideally, the complete model pipeline should be run monthly on the last Monday before the month being optimized (ie, the recommendations for March 2023 should be made on February 27th).

#### The dashboard
![image.png](/.attachments/image-f42398b8-2756-4e5c-a700-b8156eab149e.png)

## Appendix
### A. List of CDAs and respective codes and regions
[cdas_codes.csv](/.attachments/cdas_codes-1fc04f0c-619b-46e7-87df-0c03d5907180.csv)

### B. The city-based holidays feature
The holidays information come from a python library called _holidays_ and it has information about days off at a state level. In order to cross this with CDAs (which is the granularity for most tables), their customers were listed alongside their approximate latitude and longitude (from the 30_dtmart.dim_customers table). Then, with a KDTree algorithm (a searching method), each customer location is compared to Brazilian cities location (latitude and longitude table made from IBGE data) and is assigned to the closest one.

Once all customers have been placed in a city and a state, a table containing the state each CDA has customers in is made. That information is then fed to the holidays library, which is used to return how many holidays its customers will have in the week.  

### C. The quantile loss model
One of the possible ways to get an interval around the prediction is to use a model with a quantile loss function. One of the models for which that can be done is the GradientBoostingRegressor. It makes regular predictions with the confidence interval parameter (called alpha) set to 50%. An upper and lower bound prediction can be returned by using an alpha of 95% and 5% respectively (although there is no constraint that the bounds should be symmetric). However, this strategy demands different models for each bound being predicted, so it was dropped in favor of the standard deviation option, which needs a single model and also returned coherent intervals.  

More on the implementarion (and basic functionality) [here](https://medium.com/walmartglobaltech/adding-prediction-intervals-to-tree-based-models-8ea53814a4b9)


